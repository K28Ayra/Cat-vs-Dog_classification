{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5747937-7819-4e1f-b805-057b05296b56",
   "metadata": {},
   "source": [
    "# libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "558baafc-03a8-47e9-9dc5-e959b5c662c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dad7493-bd29-4e59-ad15-ffa2d8b962a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "##generators    since our dataset is very large so we work with generators i.e. data is divided into small batches and we after one batch is processed another comes in action via RAM\n",
    "\n",
    "##this code can be taken from keras official website.\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'dogs_vs_cats/train',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',    ##0 for dog and 1 for cat\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)   ##since in our dataset all the images have different sizes therefore, convert them all into same sizes\n",
    ")\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'dogs_vs_cats/test',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = 32,\n",
    "    image_size = (256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651bc072-d874-4638-8153-4f8911efed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all these images are stored in the form of numpy arrays i.e 0 to 255, so we normalize the pixel values from o to 1\n",
    "\n",
    "##normalize\n",
    "def process(image, label):\n",
    "  image = tf.cast(image/255, tf.float32)\n",
    "  return image, label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "validation_ds= validation_ds.map(process)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634f0a52-4446-45f4-bce0-58541715fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3,3), padding ='valid', activation ='relu', input_shape = (256,256,3)))    ##convolution layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))                      ##pooling layer\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), padding ='valid', activation ='relu'))     ##in total we took 3 combination of conv and pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3,3), padding ='valid', activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n",
    "\n",
    "model.add(Flatten())    ##flatten layer\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))    ##\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd3ac1a5-7a92-4a5f-9410-d503dde5f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 127, 127, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 62, 62, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 30, 30, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               14745728  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14847297 (56.64 MB)\n",
      "Trainable params: 14847297 (56.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4af7c0b-7302-4a29-8ee1-1e8ae3ce8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss = 'binary_crossentropy', metrics = ['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b3864-41dd-4c84-ac5c-e0ac76ed0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs= 10, validation_data = validation_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
